<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on A Hugo website</title>
    <link>/post/</link>
    <description>Recent content in Posts on A Hugo website</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 18 Feb 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Covariate Adjustment for Binary Outcomes in Randomized Trials</title>
      <link>/post/covariate-adjustment-for-binary-outcomes-in-randomized-trials/</link>
      <pubDate>Sun, 18 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/covariate-adjustment-for-binary-outcomes-in-randomized-trials/</guid>
      <description>IntroductionA common misconception about randomized clinical trials is that the randomization process should balance any particular covariate across the arms of the trial and that therefore there is no benefit to controlling for covariates with a regression model unless a particular covariate happens to be unbalanced by chance. Determining whether a covariate is considered unbalanced amounts to performing a significance test comparing the arms and checking to see if the p-value is below some threshold (.</description>
    </item>
    
    <item>
      <title>Introduction</title>
      <link>/post/introduction/</link>
      <pubDate>Sat, 06 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/introduction/</guid>
      <description>R Markdown</description>
    </item>
    
    <item>
      <title></title>
      <link>/post/super_learning/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/post/super_learning/</guid>
      <description>Super Learning from scratchcode{white-space: pre;}pre:not([class]) {background-color: white;}if (window.hljs) {hljs.configure({languages: []});hljs.initHighlightingOnLoad();if (document.readyState &amp;&amp; document.readyState === &#34;complete&#34;) {window.setTimeout(function() { hljs.initHighlighting(); }, 0);}}h1 {font-size: 34px;}h1.title {font-size: 38px;}h2 {font-size: 30px;}h3 {font-size: 24px;}h4 {font-size: 18px;}h5 {font-size: 16px;}h6 {font-size: 12px;}.</description>
    </item>
    
    <item>
      <title>Super Learning from scratch</title>
      <link>/post/super-learning/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/post/super-learning/</guid>
      <description>IntroductionSuper Learning is a conceptually simple way of combining predictions from different models using cross validation. It simply uses the cross-validated results to form an optimal weighted combination of predictions. Combining predictions across models, typically refered to as stacking or stacked ensembles, is not new. I’ve seen references as far back as about 30 years, though I wouldn’t be surprised if it was much older. However, as far as I know, it was only relatively recently (within 15 years) that some nice theoretical properties were proven for a particular type of stacking called super learning.</description>
    </item>
    
  </channel>
</rss>